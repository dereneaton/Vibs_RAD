{
 "metadata": {
  "name": "",
  "signature": "sha256:346aa43ddbce7fe8b5b7cd3aedf75ce5172fb5be801a05470e9265a111fc946e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Viburnum RADseq project\n",
      "### Notebook 1: Demultiplexing  \n",
      "\n",
      "-----------------------   \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Organization  \n",
      "This notebook shows how we demultiplexed sequence reads from two lanes of Illumina HiSEQ data into separate files for 95 samples based on their attached barcodes. To do this we use _pyRAD_ (v.2.15) and  allow for one base mismatch when matching barcodes. The reads are 100 bp with a 10 bp barcode followed by a 5bp restriction site, and then 85 bp of sequence data. The RAD library was prepared by Floragenex Inc., using the PstI enzyme.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "## create a working directory in which to store the demultiplexed data\n",
      "## In this case we are using a location on the Omega HPC cluster at Yale\n",
      "mkdir -p /home/fas/donoghue/de243/Viburnums/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Create a template params file  \n",
      "This file tells _pyRAD_ where to find the data and barcodes files, in addition to all other parameters used for data assembly, but here we will only need to worry about setting a few options."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "## Create template params file to use for this analysis.\n",
      "## If using an HPC cluster you may need to load Python,\n",
      "## Numpy and Scipy modules before calling pyrad\n",
      "~/pyrad_v.2.15/pyRAD -n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\tnew params.txt file created\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Setup the params file for demultiplexing\n",
      "\n",
      "The code below will substitute new values into the params file, or you could enter these by hand using a text editor. The raw data from two lanes of sequencing are currently stored in 72 compressed files in the location that is set on line 2 in the params file (on the Omega server at Yale). The \"\\*.gz\" ending indicates it will select all files ending with \".gz\". The barcodes file which matches sample names to their barcodes is in the location set on line 3 of the file. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "## substitute new params into file\n",
      "sed -i '/## 1. /c\\/home/fas/donoghue/de243/Viburnums/     ## 1. working directory ' params.txt\n",
      "sed -i '/## 2. /c\\/home/fas/donoghue/de243/RADSEQ_DATA/Viburnums/*.gz  ## 2. raw data loc. ' params.txt\n",
      "sed -i '/## 3. /c\\/home/fas/donoghue/de243/RADSEQ_DATA/barcodes/Viburnum.barcodes  ## 3. barcodes loc. ' params.txt\n",
      "sed -i '/## 7. /c\\20                          ## 7. N processors  ' params.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### View the params file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "head -n 16 params.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "==== parameter inputs for pyRAD version 2.15  ============================  affected step ==\n",
        "/home/fas/donoghue/de243/Viburnums/                   ## 1. working directory \n",
        "/home/fas/donoghue/de243/RADSEQ_DATA/Viburnums/*.gz   ## 2. raw data loc. \n",
        "/home/fas/donoghue/de243/RADSEQ_DATA/barcodes/Viburnum.barcodes  ## 3. barcodes loc. \n",
        "usearch7.0.1090_i86linux32  ## 4. command (or path) to call usearch v.7             (s3,s6)\n",
        "muscle                      ## 5. command (or path) to call muscle                  (s3,s7)\n",
        "TGCAG                       ## 6. restriction overhang (e.g., C|TGCAG -> TGCAG)     (s1,s2)\n",
        "20                          ## 7. N processors  \n",
        "6                           ## 8. Mindepth: min coverage for a cluster              (s4,s5)\n",
        "4                           ## 9. NQual: max # sites with qual < 20 (line 20)       (s2)\n",
        ".88                         ## 10. Wclust: clustering threshold as a decimal        (s3,s6)\n",
        "rad                         ## 11. Datatype: rad,gbs,ddrad,pairgbs,pairddrad,merge  (all)\n",
        "4                           ## 12. MinCov: min samples in a final locus             (s7)\n",
        "3                           ## 13. MaxSH: max inds with shared hetero site          (s7)\n",
        "c88d6m4p3                   ## 14. prefix name for final output (no spaces)         (s7)\n",
        "==== optional params below this line ===================================  affected step ==\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Demultiplex (step 1) in _pyRAD_  \n",
      "If running on a dedicated workstation you could simply run the command below, which is commented out. Because we are using an HPC cluster I will submit is instead within a `qsub` job submission form. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "#~/pyrad_v.2.15/pyRAD -p params.txt -s 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Create a qsub job submission form for HPC  \n",
      "This will save the text string below to the file \"qsub_script.sh\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "echo \"\n",
      "#!/bin/sh \n",
      "\n",
      "### Set the job name\n",
      "#PBS -N demultiplex\n",
      "\n",
      "### Combine standard error and standard out to one file.\n",
      "#PBS -j oe\n",
      "\n",
      "### Have PBS mail you results\n",
      "#PBS -m ae\n",
      "#PBS -M deren.eaton@yale.edu\n",
      "\n",
      "### Specify the queue name. \n",
      "#PBS -q fas_high\n",
      "\n",
      "### Specify N processors & N nodes.\n",
      "#PBS -l procs=20,tpn=1,mem=32gb\n",
      "\n",
      "### Specify wall-time\n",
      "#PBS -l walltime=6:00:00\n",
      "\n",
      "### Load necessary modules\n",
      "module load Langs/Python/2.7.2 \n",
      "module load Libs/NUMPY/1.8.1\n",
      "module load Libs/SCIPY/0.14.0\n",
      "\n",
      "### Run the pyRAD job\n",
      "~/pyrad_v.2.15/pyRAD -p params.txt -s 1\n",
      "\n",
      "\" > qsub_script.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Submit the job"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "qsub qsub_script.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### View the results of demultiplexing  \n",
      "This will have created two new directories in the working directory we designated on line 1 of the params file. A fastq/ directory contains the demultiplexed data files, and a stats/ directory contains a file with statistics about how many reads were demultiplexed for each sample. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Notebook 1 finished"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The compressed demultiplexed data files in the fastq/ directory are the ones that will be uploaded to the NCBI sequence read archive, and which we will used to assemble the data set in [Notebook 2](http://nbviewer.ipython.org/github/dereneaton/Vibs_RAD/blob/master/notebook_Vib2_assembly.ipynb) of this project. "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}