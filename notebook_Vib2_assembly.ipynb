{
 "metadata": {
  "name": "",
  "signature": "sha256:40a78db0bc847391c7150c65a9b2108749f12c5584e10a050dae8f73d66b12ca"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Viburnum RADseq project\n",
      "### Notebook 2: Assembling RADseq data sets\n",
      "\n",
      "-----------------------   \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Organization  \n",
      "This notebook shows how we will download sequence data from an online data base, filter reads, cluster them into stacks, and filter and call consensus sequences from those stacks. Consensus sequences will then be clustered together across different subsets of this collection of samples to yield a number of different data sets applicable to projects at different phylogenetic scales. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Download the sequence data  \n",
      "The data are downloaded from NCBI using the `wget` command into our working directory in a subdirectory called `fastq/`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Insert commands here to download data from NCBI SRA to the working directory\n",
      "## mkdir -p /home/fas/donoghue/de243/Viburnums/fastq/\n",
      "## wget xxxx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Create a new template params file for _pyRAD_ analyses  \n",
      "For simplicity we will start from a fresh template params file created with the script below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "## Create a template params file to use for this analysis.\n",
      "## Delete an old one if it already exists in this directory.\n",
      "## If running on an HPC cluster you need to load Python and \n",
      "## and the Numpy and Scipy modules before beginning.\n",
      "~/pyrad_v.2.15/pyRAD -n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Setup the params file for our analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "## substitute new params into file\n",
      "sed -i '/## 1. /c\\/home/fas/donoghue/de243/Viburnums/   ## 1. working directory ' params.txt\n",
      "sed -i '/## 7. /c\\20                          ## 7. N processors  ' params.txt\n",
      "sed -i '/## 8. /c\\6                           ## 8. Mindepth  ' params.txt\n",
      "sed -i '/## 9. /c\\4                           ## 9. NQual  ' params.txt\n",
      "sed -i '/## 10./c\\.88                         ## 10. NQual  ' params.txt\n",
      "sed -i '/## 18./c\\/home/fas/donoghue/de243/Viburnums/fastq/*.gz  ## 18. Demulti data loc. ' params.txt\n",
      "sed -i '/## 25./c\\0                           ## 25. Turn off ploidy filter ' params.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Filtering the data  \n",
      "The data are already demultiplexed so we start here from step 2 of the analysis which is to filter the data by their quality scores, and to check for adapter sequences in the reads. Arguments 9, 20, 21 and 33 from the params file are relevant to this step. We will allow up to 4 Ns in our data (line 9 = 4), the Phred quality score offset is left at the default value of 33 (line 20), and we will remove data with adapter sequences detected (line 21 = 1), and we don't include any sequences that are trimmed of adapter sequences (line 33 = default = 0). "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Create qsub job submission form  \n",
      "Similar to the job submission form we used in the first notebook, this form designates which queue we are using, the number of processors, how long it will run, the modules to load and finally the command to run step 2 in _pyRAD_. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "echo \"\n",
      "#!/bin/sh \n",
      "\n",
      "### Set the job name\n",
      "#PBS -N assembly\n",
      "\n",
      "### Combine standard error and standard out to one file.\n",
      "#PBS -j oe\n",
      "\n",
      "### Have PBS mail you results\n",
      "#PBS -m ae\n",
      "#PBS -M deren.eaton@yale.edu\n",
      "\n",
      "### Specify the queue name. \n",
      "#PBS -q fas_high\n",
      "\n",
      "### Specify N processors & N nodes.\n",
      "#PBS -l procs=20,tpn=1,mem=32gb\n",
      "\n",
      "### Specify wall-time\n",
      "#PBS -l walltime=6:00:00\n",
      "\n",
      "### Load necessary modules\n",
      "module load Langs/Python/2.7.2 \n",
      "module load Libs/NUMPY/1.8.1\n",
      "module load Libs/SCIPY/0.14.0\n",
      "\n",
      "### Run the pyRAD job\n",
      "~/pyrad_v.2.15/pyRAD -p params.txt -s 2\n",
      "\n",
      "\" > qsub_script.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Submit step2 (filtering) job "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "qsub qsub_script.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Step 3: Clustering  \n",
      "We set the clustering threshold at .88 meaning that our reads which are 90 bp long after removing the barcode will allow up to 10 base differences among sequences. This includes the maximum of four Ns we allowed in filtered reads, as well as differences among them owing to miscalled bases and true SNPs. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "## First replace step2 with step3 in the qsub script\n",
      "sed -i 's/-s 2/-s 3/g' qsub_script.sh\n",
      "\n",
      "## Set the walltime to 3 days\n",
      "sed -i '/walltime/c\\#PBS -l walltime=72:00:00 ' qsub_script.sh\n",
      "\n",
      "## and then submit the job\n",
      "qsub qsub_script.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Step 4: Estimating heterozygosity & sequencing error  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "## First replace step3 with step4 in the qsub script\n",
      "sed -i 's/-s 3/-s 4/g' qsub_script.sh\n",
      "\n",
      "## and then submit the job\n",
      "qsub qsub_script.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Step 5: Calling consensus sequences  \n",
      "For this we first remove the results for samples that are known polyploids so that base calls will be made at the estimated level of heterozygosity for diploids. We will later use the ploidy-aware GATK2 software to call genotypes for polyploids separately, but for now we treat them as diploids. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "## Using only data from known diploids according to Egolf (1956)\n",
      "## we find the following H & E which we substitute into the params file\n",
      "## rather than letting pyRAD take the value for all samples \n",
      "sed -i '/## 22./c\\0.0004691,0.0056817         ## 22. E,H ' params.txt\n",
      "\n",
      "## First replace step4 with steps5 in the qsub script\n",
      "sed -i 's/-s 4/-s 5/g' qsub_script.sh\n",
      "\n",
      "## and then submit the job\n",
      "qsub qsub_script.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Assembling data sets  \n",
      "Analyses of these data will focus at three different levels:  \n",
      "+  A backbone phylogeny of _Viburnum_  \n",
      "+  A focus on _V. cassinoides_\n",
      "+  A focus on _V. lantanoides_\n",
      "+  A focus on ..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### _V. lantanoides_ data set  \n",
      "\n",
      "We subselect only _V. cassinoides_ and a few outgroup samples. \n",
      "\n",
      "+ lantanoides_D14_Beartown_1,\n",
      "+ lantanoides_D15_Beartown_2,\n",
      "+ lantanoides_D16_Mohawk_2,\n",
      "+ lantanoides_D_17_Mohawk_3,\n",
      "+ sympodiale_D18_KFC_1932,\n",
      "+ nervosum_C4_PWS_2298,\n",
      "+ nervosum_C2_PWS_2288_2289,\n",
      "+ furcatum_combined   \n",
      "  \n",
      "\n",
      "+ carlesii_D1_BP_001\n",
      "+ plicatum_C1_MJDJP_12\n",
      "+ foetidum_D24_KFC_1942"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "## enter subset of samples onto line 15\n",
      "sed -i \"/## 15./c\\lantanoides_D14_Beartown_1,lantanoides_D15_Beartown_2,lantanoides_D16_Mohawk_2,lantanoides_D_17_Mohawk_3,sympodiale_D18_KFC_1932,nervosum_C4_PWS_2298,nervosum_C2_PWS_2288_2289,furcatum_combined,carlesii_D1_BP_001,plicatum_C1_MJDJP_12,foetidum_D24_KFC_1942    ## 15. Subset selector \" params.txt\n",
      "\n",
      "## enter the output options\n",
      "sed -i \"/## 14./c\\lantanoides_c88d6m4p3     ## 14. prefix \" params.txt\n",
      "sed -i \"/## 30./c\\n,v,k                     ## 30. outformats \" params.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "## First replace step 5 with steps 6 & 7 in the qsub script\n",
      "sed -i 's/-s 5/-s 67/g' qsub_script.sh\n",
      "\n",
      "## and then submit the job\n",
      "qsub qsub_script.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### _V. cassinoides_ data set  \n",
      "\n",
      "We will subselect only the samples of _V. cassinoides_ and a few close outgroup samples. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "+ cassinoides_ELS2,\n",
      "+ cassinoides_ELS29,\n",
      "+ cassinoides_ELS3,\n",
      "+ cassinoides_ELS50,\n",
      "+ cassinoides_ELS77,\n",
      "+ cassinoides_ELS79,\n",
      "+ cassinoides_LS54,\n",
      "+ cassinoides_YU08"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}