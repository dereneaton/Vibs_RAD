{
 "metadata": {
  "name": "",
  "signature": "sha256:b1f62cd32aaee0fcedbe66eab212883c7a8a8016a2e7556d7e0636050f20a517"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Viburnum RADseq project\n",
      "### Notebook 2: Assembling RADseq data sets\n",
      "\n",
      "-----------------------   \n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Organization  \n",
      "This notebook shows how we will download sequence data from an online data base, filter reads, cluster them into stacks, and filter and call consensus sequences from those stacks. Consensus sequences will then be clustered together across different subsets of this collection of samples to yield a number of different data sets applicable to projects at different phylogenetic scales. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Download the sequence data  \n",
      "The data are downloaded from NCBI using the `wget` command into our working directory in a subdirectory called `fastq/`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Insert commands here to download data from NCBI SRA to the working directory\n",
      "## mkdir -p /home/fas/donoghue/de243/Viburnums/fastq/\n",
      "## wget xxxx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Create a new template params file for _pyRAD_ analyses  \n",
      "For simplicity we will start from a fresh template params file created with the script below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "## Create a template params file to use for this analysis.\n",
      "## Delete an old one if it already exists in this directory.\n",
      "## If running on an HPC cluster you need to load Python and \n",
      "## and the Numpy and Scipy modules before beginning.\n",
      "~/pyrad_v.2.15/pyRAD -n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Setup the params file for our analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "## substitute new params into file\n",
      "sed -i '/## 1. /c\\/home/fas/donoghue/de243/Viburnums/                   ## 1. working directory ' params.txt\n",
      "sed -i '/## 7. /c\\20                          ## 7. N processors  ' params.txt\n",
      "sed -i '/## 8. /c\\10                          ## 8. Mindepth  ' params.txt\n",
      "sed -i '/## 9. /c\\4                           ## 9. NQual  ' params.txt\n",
      "sed -i '/## 10./c\\.88                         ## 10. NQual  ' params.txt\n",
      "sed -i '/## 18./c\\/home/fas/donoghue/de243/Viburnums/fastq/*.gz  ## 18. Demulti data loc. ' params.txt\n",
      "sed -i '/## 25./c\\0                           ## 25. Turn off ploidy filter ' params.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### View the complete params file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cat params.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Filtering the data  \n",
      "The data are already demultiplexed so we start here from step 2 of the analysis which is to filter the data by their quality scores, and to check for adapter sequences in the reads. Arguments 9, 20, 21 and 33 from the params file are relevant to this step. We will allow up to 4 Ns in our data (line 9 = 4), the Phred quality score offset is left at the default value of 33 (line 20), and we will remove data with adapter sequences detected (line 21 = 1), and we don't include any sequences that are trimmed of adapter sequences (line 33 = default = 0). "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Create qsub job submission form  \n",
      "Similar to the job submission form we used in the first notebook, this form designates which queue we are using, the number of processors, how long it will run, the modules to load and finally the command to run step 2 in _pyRAD_. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "echo \"\n",
      "#!/bin/sh \n",
      "\n",
      "### Set the job name\n",
      "#PBS -N demultiplex\n",
      "\n",
      "### Combine standard error and standard out to one file.\n",
      "#PBS -j oe\n",
      "\n",
      "### Have PBS mail you results\n",
      "#PBS -m ae\n",
      "#PBS -M deren.eaton@yale.edu\n",
      "\n",
      "### Specify the queue name. \n",
      "#PBS -q fas_high\n",
      "\n",
      "### Specify N processors & N nodes.\n",
      "#PBS -l procs=48,tpn=1,mem=32gb\n",
      "\n",
      "### Specify wall-time\n",
      "#PBS -l walltime=6:00:00\n",
      "\n",
      "### Load necessary modules\n",
      "module load Langs/Python/2.7.2 \n",
      "module load Libs/NUMPY/1.8.1\n",
      "module load Libs/SCIPY/0.14.0\n",
      "\n",
      "### Run the pyRAD job\n",
      "~/pyrad_v.2.15/pyRAD -p params.txt -s 2\n",
      "\n",
      "\" > qsub_script.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Submit step2 (filtering) job "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "qsub qsub_script.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Step 3: Clustering  \n",
      "We set the clustering threshold at .88 meaning that our reads which are 90 bp long after removing the barcode will allow up to 10 base differences among sequences. This includes the maximum of four Ns we allowed in filtered reads, as well as differences among them owing to miscalled bases and true SNPs. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "## First replace step2 with step3 in the qsub script\n",
      "sed -i 'params.txt /c\\~/pyrad_v.2.15/pyRAD -p params.txt -s 3 ' qsub_script.sh\n",
      "\n",
      "## Set the queue to a long running job queue\n",
      "sed -i '-q /c\\#PBS -q fas_very_long ' qsub_script.sh\n",
      "\n",
      "## Set the walltime to 5 days\n",
      "sed -i 'walltime/c\\#PBS -l walltime=120:00:00\n",
      "\n",
      "## and then submit the job\n",
      "qsub qsub_script.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Steps 4-5: Estimating heterozygosity & sequencing error  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "## First replace step3 with steps4-5 in the qsub script\n",
      "sed -i 'params.txt /c\\~/pyrad_v.2.15/pyRAD -p params.txt -s 45 ' qsub_script.sh\n",
      "\n",
      "## and then submit the job\n",
      "qsub qsub_script.sh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}